{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ResNet18\n",
    "import os\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision\n",
    "import common\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIRECTORY SETTINGS\n",
    "os.chdir(\".\")#Go up two directories\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'base.pt')\n",
    "IMG_NAME = 'car.jpg'\n",
    "\n",
    "#GPU is required to enable cuda\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from torchvision...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading models from torchvision...\")\n",
    "model = ResNet18()\n",
    "\n",
    "# Enable Parallel Data Processing if more than two gpu exist\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhifant/.conda/envs/HW1/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = torch.tensor(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='data', train=True, download=False, transform=None)\n",
    "model = ResNet18()\n",
    "infer_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize([0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH)) #Load best weights from file\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "image = image_loader(infer_transforms, IMG_NAME)\n",
    "output=model(image)\n",
    "predict_value,predict_idx = torch.max(output,1)\n",
    "plt.imshow(image[0].permute(1,2,0).clone().detach().numpy())\n",
    "print(train_data.classes[predict_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW1",
   "language": "python",
   "name": "hw1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
